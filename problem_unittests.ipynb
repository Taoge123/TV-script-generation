{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "\n",
    "def _print_success_message():\n",
    "    print('Tests Passed')\n",
    "\n",
    "\n",
    "def test_create_lookup_tables(create_lookup_tables):\n",
    "    with tf.Graph().as_default():\n",
    "        test_text = '''\n",
    "        Moe_Szyslak Moe's Tavern Where the elite meet to drink\n",
    "        Bart_Simpson Eh yeah hello is Mike there Last name Rotch\n",
    "        Moe_Szyslak Hold on I'll check Mike Rotch Mike Rotch Hey has anybody seen Mike Rotch lately\n",
    "        Moe_Szyslak Listen you little puke One of these days I'm gonna catch you and I'm gonna carve my name on your back with an ice pick\n",
    "        Moe_Szyslak Whats the matter Homer You're not your normal effervescent self\n",
    "        Homer_Simpson I got my problems Moe Give me another one\n",
    "        Moe_Szyslak Homer hey you should not drink to forget your problems\n",
    "        Barney_Gumble Yeah you should only drink to enhance your social skills'''\n",
    "\n",
    "        test_text = test_text.lower()\n",
    "        test_text = test_text.split()\n",
    "\n",
    "        vocab_to_int, int_to_vocab = create_lookup_tables(test_text)\n",
    "\n",
    "        # Check types\n",
    "        assert isinstance(vocab_to_int, dict),\\\n",
    "            'vocab_to_int is not a dictionary.'\n",
    "        assert isinstance(int_to_vocab, dict),\\\n",
    "            'int_to_vocab is not a dictionary.'\n",
    "\n",
    "        # Compare lengths of dicts\n",
    "        assert len(vocab_to_int) == len(int_to_vocab),\\\n",
    "            'Length of vocab_to_int and int_to_vocab don\\'t match. ' \\\n",
    "            'vocab_to_int is length {}. int_to_vocab is length {}'.format(len(vocab_to_int), len(int_to_vocab))\n",
    "\n",
    "        # Make sure the dicts have the same words\n",
    "        vocab_to_int_word_set = set(vocab_to_int.keys())\n",
    "        int_to_vocab_word_set = set(int_to_vocab.values())\n",
    "\n",
    "        assert not (vocab_to_int_word_set - int_to_vocab_word_set),\\\n",
    "            'vocab_to_int and int_to_vocab don\\'t have the same words.' \\\n",
    "            '{} found in vocab_to_int, but not in int_to_vocab'.format(vocab_to_int_word_set - int_to_vocab_word_set)\n",
    "        assert not (int_to_vocab_word_set - vocab_to_int_word_set),\\\n",
    "            'vocab_to_int and int_to_vocab don\\'t have the same words.' \\\n",
    "            '{} found in int_to_vocab, but not in vocab_to_int'.format(int_to_vocab_word_set - vocab_to_int_word_set)\n",
    "\n",
    "        # Make sure the dicts have the same word ids\n",
    "        vocab_to_int_word_id_set = set(vocab_to_int.values())\n",
    "        int_to_vocab_word_id_set = set(int_to_vocab.keys())\n",
    "\n",
    "        assert not (vocab_to_int_word_id_set - int_to_vocab_word_id_set),\\\n",
    "            'vocab_to_int and int_to_vocab don\\'t contain the same word ids.' \\\n",
    "            '{} found in vocab_to_int, but not in int_to_vocab'.format(vocab_to_int_word_id_set - int_to_vocab_word_id_set)\n",
    "        assert not (int_to_vocab_word_id_set - vocab_to_int_word_id_set),\\\n",
    "            'vocab_to_int and int_to_vocab don\\'t contain the same word ids.' \\\n",
    "            '{} found in int_to_vocab, but not in vocab_to_int'.format(int_to_vocab_word_id_set - vocab_to_int_word_id_set)\n",
    "\n",
    "        # Make sure the dicts make the same lookup\n",
    "        missmatches = [(word, id, id, int_to_vocab[id]) for word, id in vocab_to_int.items() if int_to_vocab[id] != word]\n",
    "\n",
    "        assert not missmatches,\\\n",
    "            'Found {} missmatche(s). First missmatch: vocab_to_int[{}] = {} and int_to_vocab[{}] = {}'.format(\n",
    "                len(missmatches),\n",
    "                *missmatches[0])\n",
    "\n",
    "        assert len(vocab_to_int) > len(set(test_text))/2,\\\n",
    "            'The length of vocab seems too small.  Found a length of {}'.format(len(vocab_to_int))\n",
    "\n",
    "    _print_success_message()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_get_batches(get_batches):\n",
    "    with tf.Graph().as_default():\n",
    "        test_batch_size = 128\n",
    "        test_seq_length = 5\n",
    "        test_int_text = list(range(1000*test_seq_length))\n",
    "        batches = get_batches(test_int_text, test_batch_size, test_seq_length)\n",
    "\n",
    "        # Check type\n",
    "        assert isinstance(batches, np.ndarray),\\\n",
    "            'Batches is not a Numpy array'\n",
    "\n",
    "        # Check shape\n",
    "        assert batches.shape == (7, 2, 128, 5),\\\n",
    "            'Batches returned wrong shape.  Found {}'.format(batches.shape)\n",
    "\n",
    "    _print_success_message()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_tokenize(token_lookup):\n",
    "    with tf.Graph().as_default():\n",
    "        symbols = set(['.', ',', '\"', ';', '!', '?', '(', ')', '--', '\\n'])\n",
    "        token_dict = token_lookup()\n",
    "\n",
    "        # Check type\n",
    "        assert isinstance(token_dict, dict), \\\n",
    "            'Returned type is {}.'.format(type(token_dict))\n",
    "\n",
    "        # Check symbols\n",
    "        missing_symbols = symbols - set(token_dict.keys())\n",
    "        unknown_symbols = set(token_dict.keys()) - symbols\n",
    "\n",
    "        assert not missing_symbols, \\\n",
    "            'Missing symbols: {}'.format(missing_symbols)\n",
    "        assert not unknown_symbols, \\\n",
    "            'Unknown symbols: {}'.format(unknown_symbols)\n",
    "\n",
    "        # Check values type\n",
    "        bad_value_type = [type(val) for val in token_dict.values() if not isinstance(val, str)]\n",
    "\n",
    "        assert not bad_value_type,\\\n",
    "            'Found token as {} type.'.format(bad_value_type[0])\n",
    "\n",
    "        # Check for spaces\n",
    "        key_has_spaces = [k for k in token_dict.keys() if ' ' in k]\n",
    "        val_has_spaces = [val for val in token_dict.values() if ' ' in val]\n",
    "\n",
    "        assert not key_has_spaces,\\\n",
    "            'The key \"{}\" includes spaces. Remove spaces from keys and values'.format(key_has_spaces[0])\n",
    "        assert not val_has_spaces,\\\n",
    "            'The value \"{}\" includes spaces. Remove spaces from keys and values'.format(val_has_spaces[0])\n",
    "\n",
    "        # Check for symbols in values\n",
    "        symbol_val = ()\n",
    "        for symbol in symbols:\n",
    "            for val in token_dict.values():\n",
    "                if symbol in val:\n",
    "                    symbol_val = (symbol, val)\n",
    "\n",
    "        assert not symbol_val,\\\n",
    "            'Don\\'t use a symbol that will be replaced in your tokens. Found the symbol {} in value {}'.format(*symbol_val)\n",
    "\n",
    "    _print_success_message()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_get_inputs(get_inputs):\n",
    "    with tf.Graph().as_default():\n",
    "        input_data, targets, lr = get_inputs()\n",
    "\n",
    "        # Check type\n",
    "        assert input_data.op.type == 'Placeholder',\\\n",
    "            'Input not a Placeholder.'\n",
    "        assert targets.op.type == 'Placeholder',\\\n",
    "            'Targets not a Placeholder.'\n",
    "        assert lr.op.type == 'Placeholder',\\\n",
    "            'Learning Rate not a Placeholder.'\n",
    "\n",
    "        # Check name\n",
    "        assert input_data.name == 'input:0',\\\n",
    "            'Input has bad name.  Found name {}'.format(input_data.name)\n",
    "\n",
    "        # Check rank\n",
    "        input_rank = 0 if input_data.get_shape() == None else len(input_data.get_shape())\n",
    "        targets_rank = 0 if targets.get_shape() == None else len(targets.get_shape())\n",
    "        lr_rank = 0 if lr.get_shape() == None else len(lr.get_shape())\n",
    "\n",
    "        assert input_rank == 2,\\\n",
    "            'Input has wrong rank.  Rank {} found.'.format(input_rank)\n",
    "        assert targets_rank == 2,\\\n",
    "            'Targets has wrong rank. Rank {} found.'.format(targets_rank)\n",
    "        assert lr_rank == 0,\\\n",
    "            'Learning Rate has wrong rank. Rank {} found'.format(lr_rank)\n",
    "\n",
    "    _print_success_message()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_get_init_cell(get_init_cell):\n",
    "    with tf.Graph().as_default():\n",
    "        test_batch_size_ph = tf.placeholder(tf.int32)\n",
    "        test_rnn_size = 256\n",
    "\n",
    "        cell, init_state = get_init_cell(test_batch_size_ph, test_rnn_size)\n",
    "\n",
    "        # Check type\n",
    "        assert isinstance(cell, tf.contrib.rnn.MultiRNNCell),\\\n",
    "            'Cell is wrong type.  Found {} type'.format(type(cell))\n",
    "\n",
    "        # Check for name attribute\n",
    "        assert hasattr(init_state, 'name'),\\\n",
    "            'Initial state doesn\\'t have the \"name\" attribute.  Try using `tf.identity` to set the name.'\n",
    "\n",
    "        # Check name\n",
    "        assert init_state.name == 'initial_state:0',\\\n",
    "            'Initial state doesn\\'t have the correct name. Found the name {}'.format(init_state.name)\n",
    "\n",
    "    _print_success_message()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_get_embed(get_embed):\n",
    "    with tf.Graph().as_default():\n",
    "        embed_shape = [50, 5, 256]\n",
    "        test_input_data = tf.placeholder(tf.int32, embed_shape[:2])\n",
    "        test_vocab_size = 27\n",
    "        test_embed_dim = embed_shape[2]\n",
    "\n",
    "        embed = get_embed(test_input_data, test_vocab_size, test_embed_dim)\n",
    "\n",
    "        # Check shape\n",
    "        assert embed.shape == embed_shape,\\\n",
    "            'Wrong shape.  Found shape {}'.format(embed.shape)\n",
    "\n",
    "    _print_success_message()\n",
    "\n",
    "\n",
    "def test_build_rnn(build_rnn):\n",
    "    with tf.Graph().as_default():\n",
    "        test_rnn_size = 256\n",
    "        test_rnn_layer_size = 2\n",
    "        test_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(test_rnn_size)] * test_rnn_layer_size)\n",
    "\n",
    "        test_inputs = tf.placeholder(tf.float32, [None, None, test_rnn_size])\n",
    "        outputs, final_state = build_rnn(test_cell, test_inputs)\n",
    "\n",
    "        # Check name\n",
    "        assert hasattr(final_state, 'name'),\\\n",
    "            'Final state doesn\\'t have the \"name\" attribute.  Try using `tf.identity` to set the name.'\n",
    "        assert final_state.name == 'final_state:0',\\\n",
    "            'Final state doesn\\'t have the correct name. Found the name {}'.format(final_state.name)\n",
    "\n",
    "        # Check shape\n",
    "        assert outputs.get_shape().as_list() == [None, None, test_rnn_size],\\\n",
    "            'Outputs has wrong shape.  Found shape {}'.format(outputs.get_shape())\n",
    "        assert final_state.get_shape().as_list() == [test_rnn_layer_size, 2, None, test_rnn_size],\\\n",
    "            'Final state wrong shape.  Found shape {}'.format(final_state.get_shape())\n",
    "\n",
    "    _print_success_message()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_build_nn(build_nn):\n",
    "    with tf.Graph().as_default():\n",
    "        test_input_data_shape = [128, 5]\n",
    "        test_input_data = tf.placeholder(tf.int32, test_input_data_shape)\n",
    "        test_rnn_size = 256\n",
    "        test_rnn_layer_size = 2\n",
    "        test_vocab_size = 27\n",
    "        test_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(test_rnn_size)] * test_rnn_layer_size)\n",
    "\n",
    "        logits, final_state = build_nn(test_cell, test_rnn_size, test_input_data, test_vocab_size)\n",
    "\n",
    "        # Check name\n",
    "        assert hasattr(final_state, 'name'), \\\n",
    "            'Final state doesn\\'t have the \"name\" attribute.  Are you using build_rnn?'\n",
    "        assert final_state.name == 'final_state:0', \\\n",
    "            'Final state doesn\\'t have the correct name. Found the name {}. Are you using build_rnn?'.format(final_state.name)\n",
    "\n",
    "        # Check Shape\n",
    "        assert logits.get_shape().as_list() == test_input_data_shape + [test_vocab_size], \\\n",
    "            'Outputs has wrong shape.  Found shape {}'.format(logits.get_shape())\n",
    "        assert final_state.get_shape().as_list() == [test_rnn_layer_size, 2, None, test_rnn_size], \\\n",
    "            'Final state wrong shape.  Found shape {}'.format(final_state.get_shape())\n",
    "\n",
    "    _print_success_message()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_get_tensors(get_tensors):\n",
    "    test_graph = tf.Graph()\n",
    "    with test_graph.as_default():\n",
    "        test_input = tf.placeholder(tf.int32, name='input')\n",
    "        test_initial_state = tf.placeholder(tf.int32, name='initial_state')\n",
    "        test_final_state = tf.placeholder(tf.int32, name='final_state')\n",
    "        test_probs = tf.placeholder(tf.float32, name='probs')\n",
    "\n",
    "    input_text, initial_state, final_state, probs = get_tensors(test_graph)\n",
    "\n",
    "    # Check correct tensor\n",
    "    assert input_text == test_input,\\\n",
    "        'Test input is wrong tensor'\n",
    "    assert initial_state == test_initial_state, \\\n",
    "        'Initial state is wrong tensor'\n",
    "    assert final_state == test_final_state, \\\n",
    "        'Final state is wrong tensor'\n",
    "    assert probs == test_probs, \\\n",
    "        'Probabilities is wrong tensor'\n",
    "\n",
    "    _print_success_message()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_pick_word(pick_word):\n",
    "    with tf.Graph().as_default():\n",
    "        test_probabilities = np.array([0.1, 0.8, 0.05, 0.05])\n",
    "        test_int_to_vocab = {word_i: word for word_i, word in enumerate(['this', 'is', 'a', 'test'])}\n",
    "\n",
    "        pred_word = pick_word(test_probabilities, test_int_to_vocab)\n",
    "\n",
    "        # Check type\n",
    "        assert isinstance(pred_word, str),\\\n",
    "            'Predicted word is wrong type. Found {} type.'.format(type(pred_word))\n",
    "\n",
    "        # Check word is from vocab\n",
    "        assert pred_word in test_int_to_vocab.values(),\\\n",
    "            'Predicted word not found in int_to_vocab.'\n",
    "\n",
    "\n",
    "    _print_success_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
